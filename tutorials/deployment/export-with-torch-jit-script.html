

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Export model with torch.jit.script() &mdash; WeDefense 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Calibration Tutorial in WeDefense" href="../calibration.html" />
    <link rel="prev" title="SASV Tutorial with WeDefense" href="../tasks/sasv.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/wedefense_logo_h.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#install-via-pip">Install via pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#install-locally">Install locally</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#test-your-gpu-installation">Test your GPU installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start.html">Quick Start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../quick_start.html#asvspoof2019-la-single-gpu">ASVspoof2019 LA, single GPU</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../support_status.html">WeDefense Support Status</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../support_status.html#databases">Databases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../support_status.html#augmentation">Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../support_status.html#detection">Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../support_status.html#localization">Localization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../how_to_debug.html">WeDefense - How to debug?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how_to_debug.html#commond-line">1. commond line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how_to_debug.html#vscode-cursor">2. vscode/cursor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../how_to_debug.html#option-1-launch-debug-from-a-debug-icon">2.1 Option 1: Launch debug from a debug icon</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../how_to_debug.html#option-2-prepare-a-debugging-startup-script">2.2 Option 2: Prepare a debugging startup script.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions (FAQs)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../augmentation.html">Augmentation Tutorial in WeDefense</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasks/detection.html">Spoof Detection Tutorial with WeDefense</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasks/detection.html#what-is-spoof-detection">What is Spoof Detection?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#task-definition">Task Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#why-use-llr-instead-of-raw-posterior-from-network">Why use LLR instead of raw posterior from network?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tasks/detection.html#step-by-step-implementation-in-wedefense">Step-by-Step Implementation in WeDefense</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#initial-configuration">Initial Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-1-data-preparation">Stage 1: Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-2-data-formatting-and-augmentation">Stage 2: Data Formatting and Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-3-training">Stage 3: Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-4-model-averaging-embedding-extraction">Stage 4: Model Averaging &amp; Embedding Extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-5-logit-extraction">Stage 5: Logit Extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-6-score-calibration-logits-to-llr">Stage 6: Score Calibration (Logits to LLR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#stage-7-performance-evaluation">Stage 7: Performance Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tasks/detection.html#conclusion">Conclusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../tasks/detection.html#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tasks/localization.html">Spoof Localization Tutorial with WeDefense</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasks/sasv.html">SASV Tutorial with WeDefense</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Export model with torch.jit.script()</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-command">Basic Command</a></li>
<li class="toctree-l3"><a class="reference internal" href="#arguments">Arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="#output-files">Output Files</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-1-export-detection-model-wav2vec2-large-960">Example 1: Export Detection Model (wav2vec2_large_960)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-2-export-localization-model-xlsr">Example 2: Export Localization Model (XLSR)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loading-and-using-the-exported-model">Loading and Using the Exported Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#python-example-backend-only">Python Example (Backend Only)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#c-example-libtorch-backend-only">C++ Example (LibTorch, Backend Only)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#python-example-frontend-backend-full-pipeline">Python Example (Frontend + Backend - Full Pipeline)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../calibration.html">Calibration Tutorial in WeDefense</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pruning.html">Pruning Tutorial in WeDefense</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">WeDefense</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Export model with torch.jit.script()</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/deployment/export-with-torch-jit-script.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="export-model-with-torch-jit-script">
<h1>Export model with torch.jit.script()<a class="headerlink" href="#export-model-with-torch-jit-script" title="Link to this heading"></a></h1>
<p>In this section, we describe how to export a model trained on wedefense via <code class="docutils literal notranslate"><span class="pre">torch.jit.script()</span></code>.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>The JIT export functionality in wedefense exports the <strong>backend + projection</strong> model and (when configured) a <strong>frontend</strong> model separately:</p>
<ul class="simple">
<li><p><strong>Backend + Projection</strong>: Accepts pre-extracted features and outputs classification results</p></li>
<li><p><strong>Frontend</strong>: Accepts raw waveforms and outputs multi-layer features</p></li>
</ul>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>A trained model checkpoint (<code class="docutils literal notranslate"><span class="pre">.pt</span></code> file)</p></li>
<li><p>The corresponding configuration file (<code class="docutils literal notranslate"><span class="pre">.yaml</span></code>) used during training</p></li>
<li><p>PyTorch installed</p></li>
</ul>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h2>
<section id="basic-command">
<h3>Basic Command<a class="headerlink" href="#basic-command" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>wedefense/deploy/export_jit.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--config<span class="w"> </span>&lt;path_to_config.yaml&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--checkpoint<span class="w"> </span>&lt;path_to_checkpoint.pt&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_file<span class="w"> </span>&lt;path_to_output.zip&gt;
</pre></div>
</div>
</section>
<section id="arguments">
<h3>Arguments<a class="headerlink" href="#arguments" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--config</span></code> (required): Path to the configuration YAML file used during training</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--checkpoint</span></code> (required): Path to the trained model checkpoint file</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output_file</span></code> (optional): Path where the exported JIT model will be saved. If not specified, the model will be prepared but not saved.</p></li>
</ul>
</section>
<section id="output-files">
<h3>Output Files<a class="headerlink" href="#output-files" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Backend + Projection</strong>: <code class="docutils literal notranslate"><span class="pre">&lt;output_file&gt;.zip</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">final.zip</span></code>) - Contains the backend model and projection layer</p></li>
<li><p><strong>Frontend</strong> (if applicable): <code class="docutils literal notranslate"><span class="pre">&lt;output_file_base&gt;_frontend.pt</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">final_frontend.pt</span></code>) - Contains the S3PRL frontend for feature extraction</p></li>
</ul>
<p>Note: For S3PRL frontends (wav2vec2_large_960, xlsr_53), a JIT-compatible frontend will be automatically exported.</p>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<section id="example-1-export-detection-model-wav2vec2-large-960">
<h3>Example 1: Export Detection Model (wav2vec2_large_960)<a class="headerlink" href="#example-1-export-detection-model-wav2vec2-large-960" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>wedefense/deploy/export_jit.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--config<span class="w"> </span>pretrain_models/detection_MHFA_wav2vec2_large/config.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--checkpoint<span class="w"> </span>pretrain_models/detection_MHFA_wav2vec2_large/avg_model.pt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_file<span class="w"> </span>pretrain_models/detection_MHFA_wav2vec2_large/final.zip
</pre></div>
</div>
<p>This will generate:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">final.zip</span></code> - Backend + Projection model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">final_frontend.pt</span></code> - Frontend model (wav2vec2_large_960)</p></li>
</ul>
</section>
<section id="example-2-export-localization-model-xlsr">
<h3>Example 2: Export Localization Model (XLSR)<a class="headerlink" href="#example-2-export-localization-model-xlsr" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>wedefense/deploy/export_jit.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--config<span class="w"> </span>pretrain_models/localization_MFHA_xlsr/config.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--checkpoint<span class="w"> </span>pretrain_models/localization_MFHA_xlsr/avg_model.pt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_file<span class="w"> </span>pretrain_models/localization_MFHA_xlsr/final.zip
</pre></div>
</div>
<p>This will generate:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">final.zip</span></code> - Backend + Projection model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">final_frontend.pt</span></code> - Frontend model (XLSR)</p></li>
</ul>
</section>
</section>
<section id="loading-and-using-the-exported-model">
<h2>Loading and Using the Exported Model<a class="headerlink" href="#loading-and-using-the-exported-model" title="Link to this heading"></a></h2>
<section id="python-example-backend-only">
<h3>Python Example (Backend Only)<a class="headerlink" href="#python-example-backend-only" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Load the exported JIT backend model</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;pretrain_models/detection_MHFA_wav2vec2_large/final.zip&quot;</span><span class="p">)</span>
<span class="n">backend</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Prepare input features</span>
<span class="c1"># Shape: [Batch, Dim, Frame_len, Nb_Layer]</span>
<span class="c1"># For wav2vec2_large_960: [B, 1024, T, 25]</span>
<span class="c1"># For XLSR: [B, 1024, T, 25]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>

<span class="c1"># Run inference</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">backend</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output shape: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># [1, num_classes]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="c-example-libtorch-backend-only">
<h3>C++ Example (LibTorch, Backend Only)<a class="headerlink" href="#c-example-libtorch-backend-only" title="Link to this heading"></a></h3>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/script.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/torch.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Load the backend model</span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="n">backend</span><span class="p">;</span>
<span class="w">    </span><span class="n">backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;pretrain_models/detection_MHFA_wav2vec2_large/final.zip&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="n">backend</span><span class="p">.</span><span class="n">eval</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Prepare input features: [Batch, Dim, Frame_len, Nb_Layer]</span>
<span class="w">    </span><span class="c1">// For wav2vec2_large_960 and XLSR: [B, 1024, T, 25]</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">;</span>
<span class="w">    </span><span class="n">inputs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span><span class="w"> </span><span class="mi">25</span><span class="p">}));</span>

<span class="w">    </span><span class="c1">// Run inference</span>
<span class="w">    </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">backend</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">).</span><span class="n">toTensor</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Output shape: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">sizes</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Predictions: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-std<span class="o">=</span>c++14<span class="w"> </span>inference.cpp<span class="w"> </span>-o<span class="w"> </span>inference<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-I/path/to/libtorch/include<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-L/path/to/libtorch/lib<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-ltorch<span class="w"> </span>-ltorch_cpu<span class="w"> </span>-lc10
</pre></div>
</div>
</section>
<section id="python-example-frontend-backend-full-pipeline">
<h3>Python Example (Frontend + Backend - Full Pipeline)<a class="headerlink" href="#python-example-frontend-backend-full-pipeline" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Load both frontend and backend models</span>
<span class="n">frontend</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;pretrain_models/detection_MHFA_wav2vec2_large/final_frontend.pt&quot;</span><span class="p">)</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;pretrain_models/detection_MHFA_wav2vec2_large/final.zip&quot;</span><span class="p">)</span>
<span class="n">frontend</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">backend</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Prepare raw waveform input: [Batch, Time]</span>
<span class="c1"># Example: 1 second of audio at 16kHz</span>
<span class="n">wav</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16000</span><span class="p">)</span>
<span class="n">wav_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">16000</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="c1"># Run inference</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Frontend: raw audio -&gt; multi-layer features</span>
    <span class="c1"># Output shape: [B, D, T, L] where D=1024, L=25 (num_layers)</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">feat_lengths</span> <span class="o">=</span> <span class="n">frontend</span><span class="p">(</span><span class="n">wav</span><span class="p">,</span> <span class="n">wav_lengths</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Frontend output: </span><span class="si">{</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># [1, 1024, ~50, 25]</span>

    <span class="c1"># Backend + Projection: features -&gt; classification</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">backend</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Backend output: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># [1, num_classes]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../tasks/sasv.html" class="btn btn-neutral float-left" title="SASV Tutorial with WeDefense" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../calibration.html" class="btn btn-neutral float-right" title="Calibration Tutorial in WeDefense" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, WeDefense.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>