### train configuraton

exp_dir: exp/0612_xlsr53_Nes2Net8_ASTP_num_frms150_epoch20_bz64_1e5_1e7_adam_warm3
gpus: "[0,1]"
num_avg: 5
enable_amp: False # whether enable automatic mixed precision training

seed: 42
num_epochs: 20
save_epoch_interval: 5 # save model every 5 epochs
log_batch_interval: 100 # log every 100 batchs

dataloader_args:
  batch_size: 64
  num_workers: 4
  pin_memory: False
  prefetch_factor: 8 
  drop_last: True

dataset_args:
  # the sample number which will be traversed within one epoch, if the value equals to 0,
  # the utterance number in the dataset will be used as the sample_num_per_epoch.
  sample_num_per_epoch: 0
  shuffle: True
  shuffle_args:
    shuffle_size: 2500
  filter: True
  filter_args:
    min_num_frames: 50
    max_num_frames: 400
  resample_rate: 16000
  speed_perturb: False
  num_frms: 150
  aug_prob: 0 # prob to add reverb & noise aug per sample
  frontend: "s3prl" # fbank, s3prl
  s3prl_args:
    upstream_args:
      name: xlsr_53
    download_dir: ./s3prl_hub
    multilayer_feature: True
    layerwise_feature: False #False for weighted sum
    layer: -1
    frozen: False
    frame_shift: 20
    frame_length: 20
  cmvn: True
  cmvn_args:
    norm_mean: True
    norm_var: False
  spec_aug: False
  spec_aug_args:
    num_t_mask: 1
    num_f_mask: 1
    max_t: 10
    max_f: 8
    prob: 0.6

model: SSL_BACKEND_utt_only_nes2net # starts from SSL_BACKEND (as defined in models/get_model.py) 
model_init: null
model_args:
  # feat_dim: 768
  embed_dim: 2048
  Nes_ratio: [8, 8]  # 外层嵌套数、内层 scale
  dilation: 1        # 可选，默认值也是 2
  pool_func: ASTP    # 可选，默认使用 ASTP pooling
  SE_ratio: 8      # 可选，SE模块降维比例
projection_args:
  project_type: "MSEp2sgrad" # add_margin, arc_margin, sphere, sphereface2, softmax, arc_margin_intertopk_subcenter
  scale: 32.0
  easy_margin: False

margin_scheduler: MarginScheduler
margin_update:
  initial_margin: 0.0
  final_margin: 0.0
  increase_start_epoch: 20
  fix_start_epoch: 40
  update_margin: True
  increase_type: "exp" # exp, linear

loss: MSELoss
loss_args: {} 
  #multi_scale_active: ['utt'] # ['2', '4','8','16', '32', '64', 'utt']

optimizer: Adam
optimizer_args:
  amsgrad: False

scheduler: ExponentialDecrease
scheduler_args:
  initial_lr: 0.00001
  final_lr: 0.0000001
  warm_up_epoch: 3
  warm_from_zero: True
